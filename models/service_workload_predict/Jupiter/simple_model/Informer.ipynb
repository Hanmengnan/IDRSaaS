{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_len, out_len, d_model, n_heads, e_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.in_len = in_len\n",
    "        self.out_len = out_len\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.e_layers = e_layers\n",
    "        self.dropout = dropout\n",
    "        self.pos_encoder = nn.Linear(in_len, d_model)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model, n_heads, dropout)\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, e_layers)\n",
    "        self.fc = nn.Linear(d_model, out_len)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.encoder(src)\n",
    "        output = output.transpose(0,1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_len, out_len, d_model, n_heads, d_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.in_len = in_len\n",
    "        self.out_len = out_len\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_layers = d_layers\n",
    "        self.dropout = dropout\n",
    "        self.pos_decoder = nn.Linear(in_len, d_model)\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model, n_heads, dropout)\n",
    "        self.decoder = nn.TransformerDecoder(self.decoder_layer, d_layers)\n",
    "        self.fc = nn.Linear(d_model, out_len)\n",
    "    \n",
    "    def forward(self, src, memory):\n",
    "        src = self.pos_decoder(src)\n",
    "        output = self.decoder(src, memory)\n",
    "        output = output.transpose(0,1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "class Informer(nn.Module):\n",
    "    def __init__(self, in_len, out_len, d_model, n_heads, e_layers, d_layers, dropout):\n",
    "        super(Informer, self).__init__()\n",
    "        self.in_len = in_len\n",
    "        self.out_len = out_len\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.e_layers = e_layers\n",
    "        self.d_layers = d_layers\n",
    "        self.dropout = dropout\n",
    "        self.encoder = Encoder(in_len, out_len, d_model, n_heads, e_layers, dropout)\n",
    "        self.decoder = Decoder(out_len, out_len, d_model, n_heads, d_layers, dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        encoder_output = self.encoder(src)\n",
    "        decoder_output = self.decoder(torch.zeros_like(src[:, -self.out_len:]), encoder_output)\n",
    "        return decoder_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "service_workload",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
